{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7f24150",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from d2l import torch as d2l\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c1f8464",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputfile = 'data/default/sent2vec/train_data/'\n",
    "outputfile = 'data/default/sent2vec/vec_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5d5bc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "uc = 0\n",
    "tc = 0  \n",
    "ic = 0 \n",
    "di = 0 \n",
    "sent_item_list = list()\n",
    "item_set = set()\n",
    "click_list = list()\n",
    "uoffs_list = list()\n",
    "uid_list = list()\n",
    "uoffs_list.append(0)\n",
    "uid_list.append(0)\n",
    "all_click_list = list()\n",
    "with open(os.path.join(inputfile,'train.log')) as fp:\n",
    "    for line in fp:\n",
    "        line = line[:-1]\n",
    "        line_info = line.split('\\t')\n",
    "        uid = line_info[0]\n",
    "        md5_info = line_info[1:]\n",
    "        for md5 in md5_info:\n",
    "            item_set.add(md5)\n",
    "            all_click_list.append(md5)\n",
    "            click_list.append(md5)\n",
    "            tc += 1\n",
    "        sent_item_list.append(click_list)\n",
    "        click_list = list()\n",
    "        uc += 1 \n",
    "        uoffs_list.append(tc)\n",
    "        uid_list.append(uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b576050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1562291"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sent_item_list) # 每个句子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2676e2aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1562292"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(uid_list) #所有点击item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a2d407f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29182"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(item_set) #item 集合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "541b2773",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = d2l.count_corpus(sent_item_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfc6237",
   "metadata": {},
   "source": [
    "建立词表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de62f4ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'vocab size: 29183'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = d2l.Vocab(sent_item_list)\n",
    "f'vocab size: {len(vocab)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0de44f26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[539, 241, 241, 790],\n",
       " [1543],\n",
       " [20566,\n",
       "  11494,\n",
       "  13071,\n",
       "  20566,\n",
       "  23757,\n",
       "  5991,\n",
       "  1645,\n",
       "  16316,\n",
       "  4521,\n",
       "  4497,\n",
       "  1442,\n",
       "  6132,\n",
       "  3197,\n",
       "  4732,\n",
       "  1396,\n",
       "  1659,\n",
       "  1120]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [vocab[line] for line in sent_item_list]\n",
    "corpus[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ec6e432",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_centers_and_contexts(corpus):\n",
    "    \"\"\"返回跳元模型中的中心词和上下文词，sent2vec是句子\"\"\"\n",
    "    centers, contexts = [], []\n",
    "    for line in corpus:\n",
    "        # 要形成“中心词-上下文词”对，每个句子一个词和剩余的所有此词形成\n",
    "#         if len(line) < 2:\n",
    "#             continue\n",
    "        centers += line[:len(line)-1]\n",
    "        for i in range(len(line)-1):  # 上下文窗口中间i\n",
    "            indices = list(range(i,len(line)))\n",
    "            # 从上下文词中排除中心词\n",
    "            indices.remove(i)\n",
    "            contexts.append([line[idx] for idx in indices])\n",
    "    return centers, contexts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919a0dff",
   "metadata": {},
   "source": [
    "测试形成中心词和上下文词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9291c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集 [[0, 1, 2, 3, 4, 5, 6], [7, 8, 9]]\n",
      "中心词 0 的上下文词是 [1, 2, 3, 4, 5, 6]\n",
      "中心词 1 的上下文词是 [2, 3, 4, 5, 6]\n",
      "中心词 2 的上下文词是 [3, 4, 5, 6]\n",
      "中心词 3 的上下文词是 [4, 5, 6]\n",
      "中心词 4 的上下文词是 [5, 6]\n",
      "中心词 5 的上下文词是 [6]\n",
      "中心词 7 的上下文词是 [8, 9]\n",
      "中心词 8 的上下文词是 [9]\n"
     ]
    }
   ],
   "source": [
    "tiny_dataset = [list(range(7)), list(range(7, 10))]\n",
    "print('数据集', tiny_dataset)\n",
    "for center, context in zip(*get_centers_and_contexts(tiny_dataset)):\n",
    "    print('中心词', center, '的上下文词是', context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9745a108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# “中心词-上下文词对”的数量: 234981454'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_centers, all_contexts = get_centers_and_contexts(corpus)\n",
    "f'# “中心词-上下文词对”的数量: {sum([len(contexts) for contexts in all_contexts])}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e70f8d97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8828074"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80e2c239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8828074"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_centers) # 中心词有"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adaf4f5",
   "metadata": {},
   "source": [
    "负采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d2aae1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomGenerator:\n",
    "    \"\"\"根据n个采样权重在{1,...,n}中随机抽取\"\"\"\n",
    "    def __init__(self, sampling_weights):\n",
    "        # Exclude\n",
    "        self.population = list(range(1, len(sampling_weights) + 1))\n",
    "        self.sampling_weights = sampling_weights\n",
    "        self.candidates = []\n",
    "        self.i = 0\n",
    "\n",
    "    def draw(self):\n",
    "        if self.i == len(self.candidates):\n",
    "            # 缓存k个随机采样结果\n",
    "            self.candidates = random.choices(\n",
    "                self.population, self.sampling_weights, k=10000)\n",
    "            self.i = 0\n",
    "        self.i += 1\n",
    "        return self.candidates[self.i - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7cc7c30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[241, 241, 790]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_contexts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3725278b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_negatives(all_contexts, vocab, counter, K):\n",
    "    \"\"\"返回负采样中的噪声词\"\"\"\n",
    "    # 索引为1、2、...（索引0是词表中排除的未知标记）\n",
    "    sampling_weights = [counter[vocab.to_tokens(i)]**0.75\n",
    "                        for i in range(0, len(vocab))]\n",
    "    all_negatives, generator = [], RandomGenerator(sampling_weights)\n",
    "    for contexts in all_contexts:\n",
    "        negatives = []\n",
    "        while len(negatives) <  K:\n",
    "            neg = generator.draw()\n",
    "            # 噪声词不能是上下文词\n",
    "            if neg not in contexts:\n",
    "                negatives.append(neg)\n",
    "        all_negatives.append(negatives)\n",
    "    return all_negatives\n",
    "\n",
    "all_negatives = get_negatives(all_contexts, vocab, counter, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2377fdd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch-gpu] *",
   "language": "python",
   "name": "conda-env-pytorch-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
