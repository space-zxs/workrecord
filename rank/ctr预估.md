# CTR 预估
***

**CTR的预估常用在推荐系统的排序中，给召回中的数据一个预测值，更高预测值的数据被推荐给用户的可能性越高**

**上采样/下采样 ,过采样/欠采样,解决样本不均衡问题**

过抽样（样本数量少时使用）

过抽样（也叫上采样、over-sampling）方法通过增加分类中少数类样本的数量来实现样本均衡，最直接的方法是简单复制少数类样本形成多条记录，这种方法的缺点是如果样本特征少而可能导致过拟合的问题；经过改进的过抽样方法通过在少数类中加入随机噪声、干扰数据或通过一定规则产生新的合成样本，例如SMOTE算法。

欠抽样（样本数量多时使用）

欠抽样（也叫下采样、under-sampling）方法通过减少分类中多数类样本的样本数量来实现样本均衡，最直接的方法是随机地去掉一些多数类样本来减小多数类的规模，缺点是会丢失多数类样本中的一些重要信息。

**正/负采样**

通过正负样本的惩罚权重解决样本不均衡

**协同过滤**

协同过滤（Collaborative Filtering，CF）是推荐算法的鼻祖，至今各个互联网公司中，CF都扮演着不可或缺的角色。协同过滤是根据大家的反馈、评论和意见一起对海量的信息进行过滤，从中筛选出目标用户可能感兴趣的信息的推荐过程。大致过程是，将用户与商品放入一个共现矩阵中，矩阵中的值为某用户对某件商品的点击、评价或者购买行为的度量。我们可以将用户感兴趣的所有商品向量化，记为代表该用户的向量，进而可以计算用户间的相似度。于是，可以将与某待推荐用户相似的用户所感兴趣的商品推荐给该用户。类似的，可以将对商品感兴趣的所有用户向量化，记为代表该商品的向量，进而计算物品之间的相似度。在实际的计算过程中，还应该对爆品、高销品与其他商品的相似度进行一定程度上的衰减。相似度的计算也应该进行归一化，排除数量级的影响。

协同过滤的优点是没有显式的学习过程、可解释性强、简单、速度快。其缺点也很明显：协同过滤只考虑了用户和物品的id信息，而无法将用户的属性、物品的属性、上下文考虑在内，无法挖掘用户和物品之间的隐含关系。对于没有购买或者消费的新用户，协同过滤不知如何推荐，泛化性能差，推荐头部效应比较明显。针对这些问题，MF（Matrix Factorization，矩阵分解）模型被提出来。它的核心思想是通过两个低维小矩阵（一个代表用户embedding矩阵，一个代表物品embedding矩阵）的乘积计算，来模拟真实用户点击或评分产生的大的协同信息稀疏矩阵，本质上是编码了用户和物品协同信息的降维模型。当训练完成，每个用户和物品得到对应的低维embedding表达后，如果要预测某个 对  的评分的时候，只要它们做个内积计算$$，这个得分就是预测得分。

本质上，MF模型是FM模型的特例，MF可以被认为是只有User ID 和Item ID这两个特征Fields的FM模型，MF将这两类特征通过矩阵分解，来达到将这两类特征embedding化表达的目的。而FM则可以看作是MF模型的进一步拓展，除了User ID和Item ID这两类特征外，很多其它类型的特征，都可以进一步融入FM模型里，它将所有这些特征转化为embedding低维向量表达，并计算任意两个特征embedding的内积，就是特征组合的权重，如果FM只使用User ID 和Item ID，你套到FM公式里，看看它的预测过程和MF的预测过程一样吗？

在具体的实践过程中，FM模型和MF模型相比，前者继承了后者特征embedding化的特点，同时引入了更多的Side information作为特征，将更多的特征及Side information embedding化融入FM模型中。所以表现的也更加的灵活，能够适应更多的场景。在推荐排序阶段，绝大多数只使用ID信息的模型是不实用的，没有引入Side Information（也就是除了User ID／Item ID外的很多其它可用特征的模型）是不具备实战价值的。原因很简单，大多数真实应用场景中，User/Item有很多信息可用，而协同数据只是其中的一种，引入更多特征明显对于更精准地进行个性化推荐是非常有帮助的。而如果模型不支持更多特征的便捷引入，明显受限严重，很难真正实用，这也是为何矩阵分解类的方法很少看到在排序阶段使用，通常是作为一路召回形式存在的原因。


